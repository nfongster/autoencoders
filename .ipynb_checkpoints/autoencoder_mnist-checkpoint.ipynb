{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test an autoencoder using the MNIST dataset.  Below, import the relevant libraries, set some hyperparameters, define the network architecture, and define some helper functions.  Each image in the MNIST dataset is 28 x 28 pixels, so that's why the input layer is 28x28=784 nodes.  Source: https://stats.stackexchange.com/questions/190148/building-an-autoencoder-in-tensorflow-to-surpass-pca\n",
    "\n",
    "TensorFlow and PyTorch have the same default parameters for the Adam optimizer.  In both cases, the default learning rate is 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim1, hidden_dim2, encoded_dim):\n",
    "        super(encoder, self).__init__()\n",
    "        # fce = fully-connected encoder layer\n",
    "        self.fce1 = nn.Linear(28 * 28, hidden_dim1)\n",
    "        self.fce2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fce3 = nn.Linear(hidden_dim2, encoded_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.fce1(x))\n",
    "        x = F.elu(self.fce2(x))\n",
    "        x = self.fce3(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "class decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim1, hidden_dim2, encoded_dim):\n",
    "        super(decoder, self).__init__()\n",
    "        # fcd = fully-connected decoder layer\n",
    "        self.fcd1 = nn.Linear(encoded_dim, hidden_dim2)\n",
    "        self.fcd2 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.fcd3 = nn.Linear(hidden_dim1, 28 * 28)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.fcd1(x))\n",
    "        x = F.elu(self.fcd2(x))\n",
    "        x = torch.sigmoid(self.fcd3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    \"\"\"Load and normalize the MNIST dataset.\"\"\"\n",
    "    train_data = datasets.MNIST(root='./mnist/',\n",
    "                                    train=True,\n",
    "                                    download=True,\n",
    "                                    transform=ToTensor())\n",
    "    test_data = datasets.MNIST(root='./mnist/',\n",
    "                                   train=False,\n",
    "                                   download=True,\n",
    "                                   transform=ToTensor())\n",
    "\n",
    "    print(\"Training Data: {} / Labels: {}\".format(train_data.data.size(), train_data.targets.size()))\n",
    "    print(\"Test Data: {} / Labels: {}\".format(test_data.data.size(), test_data.targets.size()))\n",
    "    train_labels = train_data.targets\n",
    "    train_data = torch.tensor(train_data.data, dtype=torch.float) / 255.\n",
    "    test_labels = test_data.targets\n",
    "    test_data = torch.tensor(test_data.data, dtype=torch.float) / 255.\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "\n",
    "def train(loader, optimizer, criterion, autoencoder):\n",
    "    \"\"\"Trains the given autoencoder using the data in loader, with a specified optimizer\n",
    "        and loss criterion.\"\"\"\n",
    "    loss_history = np.zeros((1,))\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, batch_images in enumerate(loader):\n",
    "            # Dimensions of batch_images: torch.tensor(batch_size, 28, 28)\n",
    "            optimizer.zero_grad()                # Reset the gradient\n",
    "            batch_images = torch.tensor(batch_images.view(BATCH_SIZE, 28 * 28),\n",
    "                                        dtype=torch.float) # Reshape the image dims\n",
    "            out = autoencoder(batch_images)      # Obtain output from current network\n",
    "            loss = criterion(out, batch_images)  # Compare output with original images to generate loss\n",
    "            loss.backward()                      # Perform backpropagation to get gradient\n",
    "            optimizer.step()                     # Apply gradient to update network parameters\n",
    "\n",
    "        loss_history = np.append(loss_history, loss.item())\n",
    "        print('epoch {}/{} \\t Loss: {}'.format(epoch+1, EPOCHS, loss.item()))\n",
    "    \n",
    "    return autoencoder, loss_history, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, and create a data loader for batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset, and normalize\n",
    "train_data, train_labels, test_data, test_labels = load_mnist()\n",
    "\n",
    "# For mini-batch processing.  Dimensions: (BATCH_SIZE, 28, 28)\n",
    "loader = DataLoader(dataset=train_data,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct all architectures, and train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden1 = [1024, 512, 128, 64]\n",
    "hidden2 = [512, 128, 64, 32]\n",
    "encoder_dim = 2\n",
    "network_names = ['autoencoder1.pt', 'autoencoder2.pt', 'autoencoder3.pt', 'autoencoder4.pt']\n",
    "loss_histories = np.zeros((1, EPOCHS))\n",
    "\n",
    "for i in range(4):\n",
    "    # Set up the network.  Reference name != class name, so you can reset it each iteration\n",
    "    encoder_i = encoder(hidden1[i], hidden2[i], encoder_dim)\n",
    "    decoder_i = decoder(hidden1[i], hidden2[i], encoder_dim)\n",
    "    autoencoder_i = nn.Sequential(encoder_i, decoder_i)\n",
    "    print('\\nNetwork architecture:'), print(autoencoder_i)\n",
    "    \n",
    "    # Choose optimizer and loss criterion, and train network\n",
    "    optimizer = torch.optim.Adam(autoencoder_i.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss()\n",
    "    autoencoder_i, loss_history, epoch = train(loader, optimizer, criterion, autoencoder_i)\n",
    "    loss_histories = np.row_stack((loss_histories, loss_history[1:]))\n",
    "\n",
    "    # Save network parameters\n",
    "    torch.save({'epoch': epoch,\n",
    "                'model_state_dict': autoencoder_i.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss_history': loss_history[1:]}, network_names[i])\n",
    "\n",
    "loss_histories = loss_histories[1:, :]\n",
    "np.save('loss_histories.npy', loss_histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all loss histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_histories = np.load('loss_histories.npy')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Loss History\", fontsize=22)\n",
    "for i in range(4):\n",
    "    plt.plot(np.arange(EPOCHS), loss_histories[i, :])\n",
    "plt.xlabel(\"Epoch\"), plt.ylabel(\"Mean-Squared Error\")\n",
    "plt.legend([\"Network {}\".format(i) for i in range(1, 5, 1)])\n",
    "# plt.savefig('./figures/loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the encoder and decoder portions separately.  A bit hacky, but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_encoder(encoderi, data):\n",
    "    \"\"\"Run training data through the encoder to get the encoded data.\"\"\"\n",
    "    encoded_data = np.zeros((1, encoder_dim))\n",
    "    for idx, i in enumerate(data):\n",
    "        i_encoded = encoderi(i.type(torch.FloatTensor).view(1, 28 * 28))\n",
    "        i_encoded = i_encoded.detach().numpy()\n",
    "        encoded_data = np.row_stack((encoded_data, i_encoded))\n",
    "        if (idx+1) % 5000 == 0:\n",
    "            print('{}/{} images through encoder'.format(idx+1, train_data.size(0)))\n",
    "    return encoded_data[1:, :]\n",
    "\n",
    "def apply_decoder(decoderi, data):\n",
    "    \"\"\"Run some sample data through the decoder to get images\"\"\"\n",
    "    decoded_data = []\n",
    "    for idx, i in enumerate(data):\n",
    "        i_decoded = decoderi(torch.tensor(i, dtype=torch.float))\n",
    "        decoded_data.append(i_decoded.view(28, 28).detach().numpy())\n",
    "    return decoded_data\n",
    "\n",
    "# Choose the first 10 images\n",
    "num_samples = 10\n",
    "test_image_samples = test_data[:num_samples, :]\n",
    "encoded_data_matrix = []  # 2-dimensional compressed data points (training)\n",
    "encoded_test_matrix = []  # 2-dimensional compressed data points (test)\n",
    "all_samples = []          # Results of running original images through autoencoder\n",
    "\n",
    "# Generate 8 evenly-spaced points around origin of embedded space for running through decoder\n",
    "sample_pts = np.array([[20*math.cos(a), 20*math.sin(a)] for a in np.arange(0, 2*math.pi, math.pi / 4)])\n",
    "decoded_data_matrix = []  # For storing decoder results\n",
    "\n",
    "for i in range(4):\n",
    "    # Construct an autoencoder and its encoder/decoder networks\n",
    "    encoder_i = encoder(hidden1[i], hidden2[i], encoder_dim)\n",
    "    decoder_i = decoder(hidden1[i], hidden2[i], encoder_dim)\n",
    "    autoencoder_i = nn.Sequential(encoder_i, decoder_i)\n",
    "        \n",
    "    # Load network parameters into autoencoder\n",
    "    checkpoint = torch.load(network_names[i])\n",
    "    autoencoder_i.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Get encoded data by copying network parameters of encoder portion\n",
    "    params = autoencoder_i.state_dict()\n",
    "\n",
    "    # Manually assemble encoder/decoder parameters from the autoencoder parameters\n",
    "    # (There's probably a better way to do this, but I got stuck using this method.  Plus,\n",
    "    # this way you just have to save the autoencoder parameters instead of encoder/decoder\n",
    "    # parameters in separate files)\n",
    "    enc_params = {'fce1.weight': params['0.fce1.weight'],\n",
    "             'fce1.bias': params['0.fce1.bias'],\n",
    "             'fce2.weight': params['0.fce2.weight'],\n",
    "             'fce2.bias': params['0.fce2.bias'],\n",
    "             'fce3.weight': params['0.fce3.weight'],\n",
    "             'fce3.bias': params['0.fce3.bias']}\n",
    "    encoder_i.load_state_dict(enc_params)\n",
    "    \n",
    "    dec_params = {'fcd1.weight': params['1.fcd1.weight'],\n",
    "             'fcd1.bias': params['1.fcd1.bias'],\n",
    "             'fcd2.weight': params['1.fcd2.weight'],\n",
    "             'fcd2.bias': params['1.fcd2.bias'],\n",
    "             'fcd3.weight': params['1.fcd3.weight'],\n",
    "             'fcd3.bias': params['1.fcd3.bias']}\n",
    "    decoder_i.load_state_dict(dec_params)\n",
    "    \n",
    "    # Get encoded data\n",
    "    print(\"Using encoder {}...\".format(i+1))\n",
    "    encoded_data = apply_encoder(encoder_i, train_data)\n",
    "    encoded_test = apply_encoder(encoder_i, test_data)\n",
    "    encoded_data_matrix.append(encoded_data)\n",
    "    encoded_test_matrix.append(encoded_test)\n",
    "        \n",
    "    # Run the random test images through the full autoencoder\n",
    "    print(\"Running data through autoencoder...\")\n",
    "    for j in range(num_samples):\n",
    "        # Run through full autoencoder\n",
    "        result = autoencoder_i(test_image_samples[j, :, :].view(1, 28 * 28))\n",
    "        all_samples.append(result)\n",
    "    \n",
    "    # Run some sample points through the decoder\n",
    "    print(\"Running sample points through decoder...\")\n",
    "    decoded_data_matrix.append(apply_decoder(decoder_i, sample_pts))\n",
    "\n",
    "encoded_data_matrix = np.stack(encoded_data_matrix, axis=0)\n",
    "encoded_test_matrix = np.stack(encoded_test_matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I: Apply full autoencoder\n",
    "\n",
    "Using the all_samples array, plot some sample image results.  Thanks to the following source for removing ticks: https://stackoverflow.com/questions/2176424/hiding-axis-text-in-matplotlib-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for net in range(5):\n",
    "    for sample in range(num_samples):\n",
    "        if net == 0:  # Original images\n",
    "            ax = plt.subplot(5, num_samples, sample+1)\n",
    "            top = plt.imshow(test_image_samples[sample, :, :].detach().numpy())\n",
    "            top.axes.get_xaxis().set_visible(False)\n",
    "            top.axes.get_yaxis().set_visible(False)\n",
    "            if sample == 0:\n",
    "                plt.ylabel(\"original\")\n",
    "        else:  # Autoencoder results\n",
    "            ax = plt.subplot(5, num_samples, sample+1+(net*num_samples))\n",
    "            bottom = plt.imshow(all_samples[sample+(net-1)*num_samples].view(28, 28).detach().numpy())\n",
    "            bottom.axes.get_xaxis().set_visible(False)\n",
    "            bottom.axes.get_yaxis().set_visible(False)\n",
    "plt.subplots_adjust(wspace=0, hspace=-0.8)\n",
    "# plt.savefig('./figures/digit_results.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II: Apply encoder\n",
    "\n",
    "Plot the training data in the reduced-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot embedded data\n",
    "colors = ['xkcd:grey', 'xkcd:deep blue', 'xkcd:sea blue',\n",
    "          'xkcd:robin\\'s egg blue', 'xkcd:leaf green', 'xkcd:light olive',\n",
    "          'xkcd:light yellow', 'xkcd:bright orange', 'xkcd:dull orange',\n",
    "          'xkcd:dull red']\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "encoded_data = encoded_data_matrix[:train_data.size(0), :]\n",
    "for net in range(4):\n",
    "    for i, color in enumerate(colors):\n",
    "        plt.subplot(2, 2, net+1)\n",
    "        plt.title(\"Network {}\".format(net+1), fontsize=20)\n",
    "        number = encoded_data[net, np.where(train_labels == i), :][0, :, :]\n",
    "        if net == 0 or net == 2:\n",
    "            plt.ylabel(\"Autoencoder 2\")\n",
    "        if net == 2 or net == 3:\n",
    "            plt.xlabel(\"Autoencoder 1\")\n",
    "        plt.scatter(number[:, 0], number[:, 1], label=i, c=color)\n",
    "    plt.legend()\n",
    "# plt.savefig('./figures/compressed_data.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting in a 3-dimensional reduced space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Autoencoder projecting to 3-dimensional space\")\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i, color in enumerate(colors):\n",
    "    number = encoded_data[np.where(train_labels == i), :][0, :, :]\n",
    "    ax.scatter(number[:, 0], number[:, 1], number[:, 2], label=i, c=color)\n",
    "ax.set_xlabel('Autoencoder 1')\n",
    "ax.set_ylabel('Autoencoder 2')\n",
    "ax.set_zlabel('Autoencoder 3')\n",
    "ax.view_init(azim=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(15, 8))\n",
    "for i in range(10):\n",
    "    ax=plt.subplot(2, 5, i+1)\n",
    "    other_nums = encoded_data_matrix[0, np.where(train_labels != i), :][0, :, :]\n",
    "\n",
    "    number = encoded_data_matrix[0, np.where(train_labels == i), :][0, :, :]\n",
    "    number_test = encoded_test_matrix[0, np.where(test_labels == i), :][0, :, :]\n",
    "    \n",
    "    plt.scatter(other_nums[:, 0], other_nums[:, 1], c='xkcd:Light Grey')\n",
    "    plt.scatter(number[:, 0], number[:, 1], c=colors[i])\n",
    "    plt.scatter(number_test[:, 0], number_test[:, 1], c='xkcd:White' if i==1 else 'k', marker='x', s=3)\n",
    "    ax.set_axis_off()\n",
    "# plt.savefig('./figures/test_data.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III: Apply decoder\n",
    "\n",
    "Plot the 8 sample points to be run through the decoder.  Use network 1 results (best network).  Then, run these points through the decoder to see what kinds of images the network generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Points to be run through decoder (Network 1)\", fontsize=20)\n",
    "for i in range(10):\n",
    "    number = encoded_data_matrix[0, np.where(train_labels == i), :][0, :, :]\n",
    "    plt.scatter(number[:, 0], number[:, 1], label=i, c=colors[i])\n",
    "plt.xlim([-50, 50]), plt.ylim([-50, 50])\n",
    "plt.xlabel(\"Autoencoder 1\"), plt.ylabel(\"Autoencoder 2\")\n",
    "\n",
    "for i in range(8):\n",
    "    plt.scatter(sample_pts[i, 0], sample_pts[i, 1],\n",
    "                c='xkcd:White' if i == 0 or i == 7 else 'k',\n",
    "                marker='P',\n",
    "                s=30)\n",
    "    plt.annotate(str(i+1), (sample_pts[i, 0], sample_pts[i, 1]),\n",
    "                 color='xkcd:White' if i == 0 or i == 7 else 'k',\n",
    "                 fontsize=25)\n",
    "plt.savefig('./figures/decoder_sample_pts.png', bbox_inches='tight')\n",
    "\n",
    "fig = plt.subplots(2, 4)\n",
    "for i in range(len(decoded_data_matrix[0])):\n",
    "    ax = plt.subplot(2, 4, i+1)\n",
    "    plt.title('Point {}'.format(i+1))\n",
    "    figi = plt.imshow(decoded_data_matrix[0][i])\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "# plt.savefig('./figures/decoder_results.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 418.5,
   "position": {
    "height": "525.5px",
    "left": "624px",
    "right": "20px",
    "top": "305px",
    "width": "705px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
